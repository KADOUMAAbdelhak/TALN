@inproceedings{2019-oufaida-al,
	author    = {Houda Oufaida and
	Philippe Blache and
	Omar Nouali},
	editor    = {Elisabeth M{\'{e}}tais and
	Farid Meziane and
	Sunil Vadera and
	Vijayan Sugumaran and
	Mohamad Saraee},
	title     = {A Coherence Model for Sentence Ordering},
	booktitle = {Natural Language Processing and Information Systems - 24th International
	Conference on Applications of Natural Language to Information Systems,
	{NLDB} 2019, Salford, UK, June 26-28, 2019, Proceedings},
	series    = {Lecture Notes in Computer Science},
	volume    = {11608},
	pages     = {261--273},
	publisher = {Springer},
	year      = {2019},
	url       = {https://doi.org/10.1007/978-3-030-23281-8\_21},
	doi       = {10.1007/978-3-030-23281-8\_21},
	timestamp = {Tue, 25 Jun 2019 12:32:07 +0200},
	biburl    = {https://dblp.org/rec/conf/nldb/OufaidaBN19.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{2011-recasens-hovy,
	author = {Recasens, M. and Hovy, E.},
	title = {Blanc: Implementing the Rand Index for Coreference Evaluation},
	year = {2011},
	issue_date = {October 2011},
	publisher = {Cambridge University Press},
	address = {USA},
	volume = {17},
	number = {4},
	issn = {1351-3249},
	url = {https://doi.org/10.1017/S135132491000029X},
	doi = {10.1017/S135132491000029X},
	abstract = {This paper addresses the current state of coreference resolution evaluation, in which
	different measures (notably, MUC, B3, CEAF, and ACE-value) are applied in different
	studies. None of them is fully adequate, and their measures are not commensurate.
	We enumerate the desiderata for a coreference scoring measure, discuss the strong
	and weak points of the existing measures, and propose the BiLateral Assessment of
	Noun-Phrase Coreference, a variation of the Rand index created to suit the coreference
	task. The BiLateral Assessment of Noun-Phrase Coreference rewards both coreference
	and non-coreference links by averaging the F-scores of the two types, does not ignore
	singletons-the main problem with the MUC score-and does not inflate the score in their
	presence-a problem with the B3 and CEAF scores. In addition, its fine granularity
	is consistent over the whole range of scores and affords better discrimination between
	systems.},
	journal = {Nat. Lang. Eng.},
	month = oct,
	pages = {485–510},
	numpages = {26}
}

@inproceedings{2020-yu-al,
	title = "Neural Mention Detection",
	author = "Yu, Juntao  and
	Bohnet, Bernd  and
	Poesio, Massimo",
	booktitle = "Proceedings of the 12th Language Resources and Evaluation Conference",
	month = may,
	year = "2020",
	address = "Marseille, France",
	publisher = "European Language Resources Association",
	url = "https://aclanthology.org/2020.lrec-1.1",
	pages = "1--10",
	abstract = "Mention detection is an important preprocessing step for annotation and interpretation in applications such as NER and coreference resolution, but few stand-alone neural models have been proposed able to handle the full range of mentions. In this work, we propose and compare three neural network-based approaches to mention detection. The first approach is based on the mention detection part of a state of the art coreference resolution system; the second uses ELMO embeddings together with a bidirectional LSTM and a biaffine classifier; the third approach uses the recently introduced BERT model. Our best model (using a biaffine classifier) achieves gains of up to 1.8 percentage points on mention recall when compared with a strong baseline in a HIGH RECALL coreference annotation setting. The same model achieves improvements of up to 5.3 and 6.2 p.p. when compared with the best-reported mention detection F1 on the CONLL and CRAC coreference data sets respectively in a HIGH F1 annotation setting. We then evaluate our models for coreference resolution by using mentions predicted by our best model in start-of-the-art coreference systems. The enhanced model achieved absolute improvements of up to 1.7 and 0.7 p.p. when compared with our strong baseline systems (pipeline system and end-to-end system) respectively. For nested NER, the evaluation of our model on the GENIA corpora shows that our model matches or outperforms state-of-the-art models despite not being specifically designed for this task.",
	language = "English",
	ISBN = "979-10-95546-34-4",
}


@inproceedings{2013-uryupina-moschitti,
	title = "Multilingual Mention Detection for Coreference Resolution",
	author = "Uryupina, Olga  and
	Moschitti, Alessandro",
	booktitle = "Proceedings of the Sixth International Joint Conference on Natural Language Processing",
	month = oct,
	year = "2013",
	address = "Nagoya, Japan",
	publisher = "Asian Federation of Natural Language Processing",
	url = "https://aclanthology.org/I13-1012",
	pages = "100--108",
}

@article{2013-lee-al,
	title = "Deterministic Coreference Resolution Based on Entity-Centric, Precision-Ranked Rules",
	author = "Lee, Heeyoung  and
	Chang, Angel  and
	Peirsman, Yves  and
	Chambers, Nathanael  and
	Surdeanu, Mihai  and
	Jurafsky, Dan",
	journal = "Computational Linguistics",
	volume = "39",
	number = "4",
	year = "2013",
	url = "https://aclanthology.org/J13-4004",
	doi = "10.1162/COLI_a_00152",
	pages = "885--916",
}

@book{2014-halliday-hasan,
	title={Cohesion in English},
	author={Halliday, M.A.K. and Hasan, R.},
	isbn={9781317869603},
	series={English Language Series},
	url={https://books.google.dz/books?id=rAOtAgAAQBAJ},
	year={2014},
	publisher={Taylor \& Francis}
}

@book{2015-schmolz,
	author = {Helene Schmolz},
	doi = {doi:10.1515/9783110416756},
	url = {https://doi.org/10.1515/9783110416756},
	title = {Anaphora Resolution and Text Retrieval},
	year = {2015},
	publisher = {De Gruyter},
	ISBN = {978-3-11-041675-6}
}

@inproceedings{97-reynar-ratnaparkhi,
	author = {Reynar, Jeffrey C. and Ratnaparkhi, Adwait},
	title = {A maximum entropy approach to identifying sentence boundaries},
	booktitle = {Proceedings of the fifth conference on Applied natural language processing},
	series = {ANLC '97},
	year = {1997},
	location = {Washington, DC},
	pages = {16--19},
	numpages = {4},
	url = {http://dx.doi.org/10.3115/974557.974561},
	doi = {10.3115/974557.974561},
	acmid = {974561},
	publisher = {Association for Computational Linguistics},
	address = {Stroudsburg, PA, USA},
}

@inproceedings{89-riley,
	author = {Riley, Michael D.},
	title = {Some applications of tree-based modelling to speech and language},
	booktitle = {Proceedings of the workshop on Speech and Natural Language},
	series = {HLT '89},
	year = {1989},
	isbn = {1-55860-112-0},
	location = {Cape Cod, Massachusetts},
	pages = {339--352},
	numpages = {14},
	url = {http://dx.doi.org/10.3115/1075434.1075492},
	doi = {10.3115/1075434.1075492},
	acmid = {1075492},
	publisher = {Association for Computational Linguistics},
	address = {Stroudsburg, PA, USA},
}

@article{97-palmer-hearst,
	author = {Palmer, David D. and Hearst, Marti A.},
	title = {Adaptive multilingual sentence boundary disambiguation},
	journal = {Comput. Linguist.},
	issue_date = {June 1997},
	volume = {23},
	number = {2},
	month = jun,
	year = {1997},
	issn = {0891-2017},
	pages = {241--267},
	numpages = {27},
	url = {http://dl.acm.org/citation.cfm?id=972695.972697},
	acmid = {972697},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA},
}

@inproceedings{97-palmer,
	author = {Palmer, David D.},
	title = {A trainable rule-based algorithm for word segmentation},
	booktitle = {Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter of the Association for Computational Linguistics},
	series = {ACL '98},
	year = {1997},
	location = {Madrid, Spain},
	pages = {321--328},
	numpages = {8},
	url = {http://dx.doi.org/10.3115/976909.979658},
	doi = {10.3115/976909.979658},
	acmid = {979658},
	publisher = {Association for Computational Linguistics},
	address = {Stroudsburg, PA, USA},
}

@Misc{2018-texas,
	author = {Raymond J. Mooney},
	title = {Introduction},
	howpublished = {Cours "CS 388: Natural Language Processing"},
	year = {2018},
	note = {University of Texas at Austin},
	OPTannote = {annote},
}

@ARTICLE{1951-shannon,
	author={C. E. {Shannon}},
	journal={The Bell System Technical Journal}, 
	title={Prediction and entropy of printed English}, 
	year={1951},
	volume={30},
	number={1},
	pages={50-64},
}

@article{1961-joshi,
	title={Computation of syntactic structure},
	author={Joshi, Aravind K},
	journal={Advances in Documentation and Library Science},
	volume={3},
	number={part 2},
	pages={831--840},
	year={1961}
}

@book{1962-harris,
	title={String analysis of sentence structure},
	author={Harris, Zellig Sabbettai},
	number={1},
	year={1962},
	publisher={Mouton}
}

@Misc{1964-bobrow,
	title={Natural Language Input for a Computer Problem Solving System},
	author={Bobrow, Daniel G},
	year={1964},
	publisher={Massachusetts Institute of Technology},
	type = {PhD},
	institution = {Massachusetts Institute of Technology},
}


@article{1958-luhn,
	title={The automatic creation of literature abstracts},
	author={Luhn, Hans Peter},
	journal={IBM Journal of research and development},
	volume={2},
	number={2},
	pages={159--165},
	year={1958},
	publisher={Ibm}
}

@Inbook{1994-Jones,
	author="Jones, Karen Sparck",
	editor="Zampolli, Antonio
	and Calzolari, Nicoletta
	and Palmer, Martha",
	title="Natural Language Processing: A Historical Review",
	bookTitle="Current Issues in Computational Linguistics: In Honour of Don Walker",
	year="1994",
	publisher="Springer Netherlands",
	address="Dordrecht",
	pages="3--16",
	abstract="This paper reviews natural language processing (NLP) from the late 1940's to the present, seeking to identify its successive trends as these reflect concerns with different problems or the pursuit of different approaches to solving these problems and building systems as wholes. The review distinguishes four phases in the history of NLP, characterised respectively by an emphasis on machine translation, by the influence of artificial intelligence, by the adoption of a logico-grammatical style, and by an attack on massive language data. The account considers the significant and salient work in each phase, and concludes with an assessment of where we stand after more than forty years of effort in the field.",
	isbn="978-0-585-35958-8",
	doi="10.1007/978-0-585-35958-8_1",
	url="https://doi.org/10.1007/978-0-585-35958-8_1"
}

@Misc{1971-winograd,
	author = {Winograd, Terry},
	title = {Procedures as a Representation for Data in a Computer Program for Understanding Natural Language},
	type = {Technical report},
	institution = {MIT},
	year = {1971},
}

@incollection{1975-schank,
	title = "CHAPTER 1 - MARGIE",
	editor = "ROGER C. SCHANK",
	booktitle = "Conceptual Information Processing",
	publisher = "North-Holland",
	pages = "1 - 4",
	year = "1975",
	isbn = "978-1-4832-2973-7",
	doi = "https://doi.org/10.1016/B978-1-4832-2973-7.50005-5",
	url = "http://www.sciencedirect.com/science/article/pii/B9781483229737500055",
	author = "ROGER C. SCHANK"
}

@ARTICLE{1975-baker,
	author={J. {Baker}},
	journal={IEEE Transactions on Acoustics, Speech, and Signal Processing}, 
	title={The DRAGON system--An overview}, 
	year={1975},
	volume={23},
	number={1},
	pages={24-29},
}

@article{1987-sag-pollard,
	title={Information-based syntax and semantics},
	author={Sag, Ivan A and Pollard, Carl},
	journal={CSLI lecture notes},
	volume={13},
	year={1987}
}

@inproceedings{1988-church,
	author = {Church, Kenneth Ward},
	title = {A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text},
	year = {1988},
	publisher = {Association for Computational Linguistics},
	address = {USA},
	url = {https://doi.org/10.3115/974235.974260},
	doi = {10.3115/974235.974260},
	booktitle = {Proceedings of the Second Conference on Applied Natural Language Processing},
	pages = {136–143},
	numpages = {8},
	location = {Austin, Texas},
	series = {ANLC ’88}
}


@article{1990-brown-al,
	title = "A Statistical Approach to Machine Translation",
	author = "Brown, Peter F.  and
	Cocke, John  and
	Della Pietra, Stephen A.  and
	Della Pietra, Vincent J.  and
	Jelinek, Fredrick  and
	Lafferty, John D.  and
	Mercer, Robert L.  and
	Roossin, Paul S.",
	journal = "Computational Linguistics",
	volume = "16",
	number = "2",
	year = "1990",
	url = "https://www.aclweb.org/anthology/J90-2002",
	pages = "79--85",
}

@InProceedings{1996-magerman,
	author="Magerman, David M.",
	editor="Miclet, Laurent
	and de la Higuera, Colin",
	title="Learning grammatical structure using statistical decision-trees",
	booktitle="Grammatical Interference: Learning Syntax from Sentences",
	year="1996",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="1--21",
	abstract="In this paper, I describe SPATTER, a statistical parser based on decision-tree learning techniques which avoids the difficulties of grammar development simply by having no grammar. Instead, the parser is driven by statistical pattern recognizers, in the form of decision trees, trained on correctly parsed sentences. This approach to grammatical inference results in a parser which constructs a complete parse for every sentence and achieves accuracy rates far better than any previously published result.",
	isbn="978-3-540-70678-6"
}

@inproceedings{1980-bobrow,
	title={Knowledge Representation for Syntactic/Semantic Processing.},
	author={Bobrow, Robert J and Webber, Bonnie L},
	booktitle={AAAI},
	pages={316--323},
	year={1980}
}

@inproceedings{1986-jacobs,
	author = {Jacobs, Paul S.},
	title = {Language Analysis in Not-so-Limited Domains},
	year = {1986},
	isbn = {0818647434},
	publisher = {IEEE Computer Society Press},
	address = {Washington, DC, USA},
	booktitle = {Proceedings of 1986 ACM Fall Joint Computer Conference},
	pages = {247–252},
	numpages = {6},
	location = {Dallas, Texas, USA},
	series = {ACM ’86}
}

@article{1995-miller,
	title={WordNet: a lexical database for English},
	author={Miller, George A},
	journal={Communications of the ACM},
	volume={38},
	number={11},
	pages={39--41},
	year={1995},
	publisher={ACM New York, NY, USA}
}

@article{2003-bengio-al,
	title={A neural probabilistic language model},
	author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
	journal={Journal of machine learning research},
	volume={3},
	number={Feb},
	pages={1137--1155},
	year={2003}
}

@article{1993-marcus-al,
	title = "Building a Large Annotated Corpus of {E}nglish: The {P}enn {T}reebank",
	author = "Marcus, Mitchell P.  and
	Santorini, Beatrice  and
	Marcinkiewicz, Mary Ann",
	journal = "Computational Linguistics",
	volume = "19",
	number = "2",
	year = "1993",
	url = "https://www.aclweb.org/anthology/J93-2004",
	pages = "313--330",
}

@inproceedings{2014-lebret-collobert,
	title = "Word Embeddings through Hellinger {PCA}",
	author = "Lebret, R{\'e}mi  and
	Collobert, Ronan",
	booktitle = "Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics",
	month = apr,
	year = "2014",
	address = "Gothenburg, Sweden",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/E14-1051",
	doi = "10.3115/v1/E14-1051",
	pages = "482--490",
}

@article{2018-devlin-al,
	title={Bert: Pre-training of deep bidirectional transformers for language understanding},
	author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	journal={arXiv preprint arXiv:1810.04805},
	year={2018}
}

@article{2018-peters-al,
	title={Deep contextualized word representations},
	author={Peters, Matthew E and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
	journal={arXiv preprint arXiv:1802.05365},
	year={2018}
}

@inproceedings{2018-howard-ruder,
	title = "Universal Language Model Fine-tuning for Text Classification",
	author = "Howard, Jeremy  and
	Ruder, Sebastian",
	booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
	month = jul,
	year = "2018",
	address = "Melbourne, Australia",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/P18-1031",
	doi = "10.18653/v1/P18-1031",
	pages = "328--339",
	abstract = "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24{\%} on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100 times more data. We open-source our pretrained models and code.",
}

@misc{2018-radford-al,
	title={Improving language understanding by generative pre-training},
	author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
	year={2018}
}

@article{2019-lample-conneau,
	title={Cross-lingual language model pretraining},
	author={Lample, Guillaume and Conneau, Alexis},
	journal={arXiv preprint arXiv:1901.07291},
	year={2019}
}

@book{2009-ball,
	author = {Rodney Ball},
	title = {Introduction to Phonetics for Students of English, French, German and Spanish},
	year = {2009},
	publisher = {HumBox Project},
}

@book{2009-lieber,
	author = {Rochelle Lieber},
	title = {Introducing Morphology},
	year = {2009},
	publisher = {Cambridge University Press},
	isbn = {978-0-511-77018-0},
}

@book{2018-anderson,
	author = {Catherine Anderson},
	title = {Essentials of Linguistics},
	year = {2018},
	publisher = {McMaster University},
}

@book{2011-aronoff-fudeman,
	author = {Mark Aronoff and Kirsten Fudeman},
	title = {Introducing Morphology},
	year = {2011},
	publisher = {Wiley-Blackwell Publishing Ltd},
	isbn = {978-1-4051-9467-9},
}


@Misc{2014-univ,
	author = {{Universal Dependencies contributors}},
	title = {Universal Dependencies},
	howpublished = {Site web},
	year = {2014},
	note = {URL : \url{https://universaldependencies.org/} [visité le 3 juillet 2020]},
}


@book{2001-akmajian,
	author = {Adrian Akmajian and Richard A. Demers and Ann K. Farmer and Robert M. Harnish},
	title = {Linguistics, An Introduction to Language and Communication},
	year = {2001},
	publisher = {The MIT Press},
	edition = {fifth},
}

@article{1988-blake, 
	title={Basic word order. Functional principles}, 
	volume={24}, 
	DOI={10.1017/S0022226700011646}, 
	number={1}, 
	journal={Journal of Linguistics}, 
	publisher={Cambridge University Press}, 
	author={Blake, Barry B.}, 
	year={1988}, 
	pages={213–217}
}

@book{2008-tellier,
	title={Introduction au TALN et à l'ingénierie linguistique},
	author={Tellier, Isabelle},
	year={2008},
	publisher={Université de Lille3}
}

@book{2019-jurafsky-martin,
	author = {Jurafsky, Dan and Martin, James H.},
	title = {Speech and Language Processing},
	year = {2019},
	url = {https://web.stanford.edu/~jurafsky/slp3/},
}

@book{2018-kroeger,
	title = {Analyzing meaning: An introduction to semantics and pragmatics},
	year = {2018},
	author = {Paul Kroeger},
	publisher = {Language Science Press}, 
	edition = {2nd},
	isbn = {978-3-96110-034-7},
	doi = {10.5281/zenodo.1164112},
	location = {Berlin},
}

@book{2007-hurford-al,
	title = {Semantics: A Coursebook},
	year = {2007},
	author = {James R. Hurford and Brendan Heasley and Michael B. Smith},
	publisher = {Cambridge University Press}, 
	edition = {2nd},
	isbn = {978-0-511-28489-2},
}

@book{2002-russell-norvig,
	title = {Artificial Intelligence: A Modern Approach},
	year = {2002},
	author = {Stuart Russell and Peter Norvig},
	publisher = {Prentice Hall}, 
	edition = {2nd},
}

@book{2006-griffiths,
	title = {An introduction to English semantics and pragmatics},
	year = {2006},
	author = {Patrick Griffiths},
	publisher = {Edinburgh university press}, 
}

@article{1979-Grice,
	title={Logique et conversation},
	author={H. Paul Grice},
	journal={Communications},
	year={1979},
	volume={30},
	pages={57-72}
}

@book{1962-austin,
	title = {How to do things with words},
	year = {1962},
	author = {John Langshaw Austin},
	publisher = {Oxford university press}, 
}

@inproceedings{leidner-plachouras-2017-ethical,
	title = "Ethical by Design: Ethics Best Practices for Natural Language Processing",
	author = "Leidner, Jochen L.  and
	Plachouras, Vassilis",
	booktitle = "Proceedings of the First {ACL} Workshop on Ethics in Natural Language Processing",
	month = apr,
	year = "2017",
	address = "Valencia, Spain",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/W17-1604",
	doi = "10.18653/v1/W17-1604",
	pages = "30--40",
	abstract = "Natural language processing (NLP) systems analyze and/or generate human language, typically on users{'} behalf. One natural and necessary question that needs to be addressed in this context, both in research projects and in production settings, is the question how ethical the work is, both regarding the process and its outcome. Towards this end, we articulate a set of issues, propose a set of best practices, notably a process featuring an ethics review board, and sketch and how they could be meaningfully applied. Our main argument is that ethical outcomes ought to be achieved by design, i.e. by following a process aligned by ethical values. We also offer some response options for those facing ethics issues. While a number of previous works exist that discuss ethical issues, in particular around big data and machine learning, to the authors{'} knowledge this is the first account of NLP and ethics from the perspective of a principled process.",
}

@inbook{2020-bahja,
	author = {Mohammed Bahja},
	title = {Natural Language Processing Applications in Business},
	booktitle = {E-Business},
	year = {2020},
	publiser = {intechopen},
	doi = {10.5772/intechopen.92203}
}

@misc{sadasivam2020memebot,
	title={memeBot: Towards Automatic Image Meme Generation},
	author={Aadhavan Sadasivam and Kausic Gunasekar and Hasan Davulcu and Yezhou Yang},
	year={2020},
	eprint={2004.14571},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}


@book{2010-indurkhya-damerau,
	author = {Indurkhya, Nitin and Damerau, Fred J.},
	title = {Handbook of Natural Language Processing},
	year = {2010},
	isbn = {1420085921},
	publisher = {Chapman \& Hall/CRC},
	edition = {2nd}
}

@article{1980-porter,
	title={An algorithm for suffix stripping.},
	author={Porter, Martin F and others},
	journal={Program},
	volume={14},
	number={3},
	pages={130--137},
	year={1980},
	publisher={Citeseer}
}

@Misc{2020-jurafsky,
	author = {Jurafsky, Dan},
	title = {Language Modeling},
	howpublished = {Cours "CS 124: From Languages to Information"},
	year = {2020},
	note = {Stanford University},
	OPTannote = {annote},
}

@Misc{2020-smith,
	author = {Noah Smith},
	title = {Neural Models},
	howpublished = {Cours "Natural Language Processing (CSE 517)"},
	year = {2020},
	note = {University of Washington},
	OPTannote = {annote},
}

@article {2003-bengio-al,
	author = {Yoshua Bengio and Réjean Ducharme annd Pascal Vincent and Christian Jauvin},
	title = {A neural probabilistic language model},
	journal = {Journal of Machine Learning Research},
	year = {2003},
	note = {URL: \url{http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf}},
}

@inproceedings{2010-mokolov-al,
	author = {Tomas Mikolov and Martin Karafi\'{a}t and Lukas Burget and Jan Cernock\`{y} and Sanjeev
	Khudanpur},
	title = {Recurrent neural network based language model},
	booktitle = {In Proc. of Interspeech},
	year = {2010},
	note = {URL: \url{http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf}},
}


@book{2018-eisenstein,
	author = {Jacob Eisenstein},
	title = {Natural Language Processing},
	year = {2018},
}

@Inbook{2003-taylor,
	author="Taylor, Ann
	and Marcus, Mitchell
	and Santorini, Beatrice",
	editor="Abeill{\'e}, Anne",
	title="The Penn Treebank: An Overview",
	bookTitle="Treebanks: Building and Using Parsed Corpora",
	year="2003",
	publisher="Springer Netherlands",
	address="Dordrecht",
	pages="5--22",
	abstract="The Penn Treebank, in its eight years of operation (1989--1996), produced approximately 7 million words of part-of-speech tagged text, 3 million words of skeletally parsed text, over 2 million words of text parsed for predicateargument structure, and 1.6 million words of transcribed spoken text annotated for speech disfluencies. This paper describes the design of the three annotation schemes used by the Treebank: POS tagging, syntactic bracketing, and disfluency annotation and the methodology employed in production. All available Penn Treebank materials are distributed by the Linguistic Data Consortium http://www.ldc.upenn.edu.",
	isbn="978-94-010-0201-1",
	doi="10.1007/978-94-010-0201-1_1",
	url="https://doi.org/10.1007/978-94-010-0201-1_1"
}

@inproceedings{2012-petrov-al,
	title = "A Universal Part-of-Speech Tagset",
	author = "Petrov, Slav  and
	Das, Dipanjan  and
	McDonald, Ryan",
	booktitle = "Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12)",
	month = may,
	year = "2012",
	address = "Istanbul, Turkey",
	publisher = "European Language Resources Association (ELRA)",
	url = "http://www.lrec-conf.org/proceedings/lrec2012/pdf/274_Paper.pdf",
	pages = "2089--2096",
	abstract = "To facilitate future research in unsupervised induction of syntactic structure and to standardize best-practices, we propose a tagset that consists of twelve universal part-of-speech categories. In addition to the tagset, we develop a mapping from 25 different treebank tagsets to this universal set. As a result, when combined with the original treebank data, this universal tagset and mapping produce a dataset consisting of common parts-of-speech for 22 different languages. We highlight the use of this resource via three experiments, that (1) compare tagging accuracies across languages, (2) present an unsupervised grammar induction approach that does not use gold standard part-of-speech tags, and (3) use the universal tags to transfer dependency parsers between languages, achieving state-of-the-art results.",
}

@inproceedings{2014-de-marneffe-al,
	title = "Universal {S}tanford dependencies: A cross-linguistic typology",
	author = "de Marneffe, Marie-Catherine  and
	Dozat, Timothy  and
	Silveira, Natalia  and
	Haverinen, Katri  and
	Ginter, Filip  and
	Nivre, Joakim  and
	Manning, Christopher D.",
	booktitle = "Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14)",
	month = may,
	year = "2014",
	address = "Reykjavik, Iceland",
	publisher = "European Language Resources Association (ELRA)",
	url = "http://www.lrec-conf.org/proceedings/lrec2014/pdf/1062_Paper.pdf",
	pages = "4585--4592",
	abstract = "Revisiting the now de facto standard Stanford dependency representation, we propose an improved taxonomy to capture grammatical relations across languages, including morphologically rich ones. We suggest a two-layered taxonomy: a set of broadly attested universal grammatical relations, to which language-specific relations can be added. We emphasize the lexicalist stance of the Stanford Dependencies, which leads to a particular, partially new treatment of compounding, prepositions, and morphology. We show how existing dependency schemes for several languages map onto the universal taxonomy proposed here and close with consideration of practical implications of dependency representation choices for NLP applications, in particular parsing.",
}

@ARTICLE{1990-deerwester-al,
	author = {Scott Deerwester and Susan T. Dumais and George W. Furnas and Thomas K. Landauer and Richard Harshman},
	title = {Indexing by latent semantic analysis},
	journal = {JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE},
	year = {1990},
	volume = {41},
	number = {6},
	pages = {391--407}
}

@misc{2013-mikolov-al,
	title={Efficient Estimation of Word Representations in Vector Space},
	author={Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
	year={2013},
	note={URL: \url{https://arxiv.org/abs/1301.3781}},
	eprint={1301.3781},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}

@inproceedings{2014-pennington-al,
	title = "{G}lo{V}e: Global Vectors for Word Representation",
	author = "Pennington, Jeffrey  and
	Socher, Richard  and
	Manning, Christopher",
	booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
	month = oct,
	year = "2014",
	address = "Doha, Qatar",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/D14-1162",
	doi = "10.3115/v1/D14-1162",
	pages = "1532--1543",
}

@inproceedings{2018-peters-al,
	title = "Deep Contextualized Word Representations",
	author = "Peters, Matthew  and
	Neumann, Mark  and
	Iyyer, Mohit  and
	Gardner, Matt  and
	Clark, Christopher  and
	Lee, Kenton  and
	Zettlemoyer, Luke",
	booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
	month = jun,
	year = "2018",
	address = "New Orleans, Louisiana",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/N18-1202",
	doi = "10.18653/v1/N18-1202",
	pages = "2227--2237",
	abstract = "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
}

@misc{2015-kim-al,
	title={Character-Aware Neural Language Models},
	author={Yoon Kim and Yacine Jernite and David Sontag and Alexander M. Rush},
	year={2015},
	eprint={1508.06615},
	note = {URL :  \url{https://arxiv.org/abs/1508.06615}},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}

@article{2002-finkelstein-al,
	title = {Placing Search in Context: The Concept Revisited},
	year = {2002},
	author={Lev Finkelstein and Evgeniy Gabrilovich and Yossi Matias and Ehud Rivlin and Zach Solan and Gadi Wolfman and Eytan Ruppin},
	issue_date = {January 2002},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {20},
	number = {1},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/503104.503110},
	doi = {10.1145/503104.503110},
	journal = {ACM Trans. Inf. Syst.},
	month = jan,
	pages = {116–131},
	numpages = {16},
	keywords = {invisible web, statistical natural language processing, Search, context, semantic processing}
}

@article{2015-hill-al,
	title = "{S}im{L}ex-999: Evaluating Semantic Models With (Genuine) Similarity Estimation",
	author = "Hill, Felix  and
	Reichart, Roi  and
	Korhonen, Anna",
	journal = "Computational Linguistics",
	volume = "41",
	number = "4",
	month = dec,
	year = "2015",
	url = "https://www.aclweb.org/anthology/J15-4004",
	doi = "10.1162/COLI_a_00237",
	pages = "665--695",
}

@inproceedings{2013-mikolov-al2,
	title = "Linguistic Regularities in Continuous Space Word Representations",
	author = "Mikolov, Tomas  and
	Yih, Wen-tau  and
	Zweig, Geoffrey",
	booktitle = "Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
	month = jun,
	year = "2013",
	address = "Atlanta, Georgia",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/N13-1090",
	pages = "746--751",
}

@article {2017-caliskan-al,
	author = {Caliskan, Aylin and Bryson, Joanna J. and Narayanan, Arvind},
	title = {Semantics derived automatically from language corpora contain human-like biases},
	volume = {356},
	number = {6334},
	pages = {183--186},
	year = {2017},
	doi = {10.1126/science.aal4230},
	publisher = {American Association for the Advancement of Science},
	abstract = {AlphaGo has demonstrated that a machine can learn how to do things that people spend many years of concentrated study learning, and it can rapidly learn how to do them better than any human can. Caliskan et al. now show that machines can learn word associations from written texts and that these associations mirror those learned by humans, as measured by the Implicit Association Test (IAT) (see the Perspective by Greenwald). Why does this matter? Because the IAT has predictive value in uncovering the association between concepts, such as pleasantness and flowers or unpleasantness and insects. It can also tease out attitudes and beliefs{\textemdash}for example, associations between female names and family or male names and career. Such biases may not be expressed explicitly, yet they can prove influential in behavior.Science, this issue p. 183; see also p. 133Machine learning is a means to derive artificial intelligence by discovering patterns in existing data. Here, we show that applying machine learning to ordinary human language results in human-like semantic biases. We replicated a spectrum of known biases, as measured by the Implicit Association Test, using a widely used, purely statistical machine-learning model trained on a standard corpus of text from the World Wide Web. Our results indicate that text corpora contain recoverable and accurate imprints of our historic biases, whether morally neutral as toward insects or flowers, problematic as toward race or gender, or even simply veridical, reflecting the status quo distribution of gender with respect to careers or first names. Our methods hold promise for identifying and addressing sources of bias in culture, including technology.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/356/6334/183},
	eprint = {https://science.sciencemag.org/content/356/6334/183.full.pdf},
	journal = {Science}
}

@article{2019-turc-al,
	title={Well-Read Students Learn Better: On the Importance of Pre-training Compact Models},
	author={Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	journal={arXiv preprint arXiv:1908.08962v2 },
	year={2019},
	note={URL: \url{https://arxiv.org/abs/1908.08962}}
}

@inproceedings{2019-devlin-al,
	title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
	author = "Devlin, Jacob  and
	Chang, Ming-Wei  and
	Lee, Kenton  and
	Toutanova, Kristina",
	booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
	month = jun,
	year = "2019",
	address = "Minneapolis, Minnesota",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/N19-1423",
	doi = "10.18653/v1/N19-1423",
	pages = "4171--4186",
	abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@article{2016-wu-al,
	author    = {Yonghui Wu and
	Mike Schuster and
	Zhifeng Chen and
	Quoc V. Le and
	Mohammad Norouzi and
	Wolfgang Macherey and
	Maxim Krikun and
	Yuan Cao and
	Qin Gao and
	Klaus Macherey and
	Jeff Klingner and
	Apurva Shah and
	Melvin Johnson and
	Xiaobing Liu and
	Lukasz Kaiser and
	Stephan Gouws and
	Yoshikiyo Kato and
	Taku Kudo and
	Hideto Kazawa and
	Keith Stevens and
	George Kurian and
	Nishant Patil and
	Wei Wang and
	Cliff Young and
	Jason Smith and
	Jason Riesa and
	Alex Rudnick and
	Oriol Vinyals and
	Greg Corrado and
	Macduff Hughes and
	Jeffrey Dean},
	title     = {Google's Neural Machine Translation System: Bridging the Gap between
	Human and Machine Translation},
	journal   = {CoRR},
	volume    = {abs/1609.08144},
	year      = {2016},
	url       = {http://arxiv.org/abs/1609.08144},
	archivePrefix = {arXiv},
	eprint    = {1609.08144},
	timestamp = {Thu, 14 Mar 2019 09:34:18 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/WuSCLNMKCGMKSJL16.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{2017-vaswani-al,
	author    = {Ashish Vaswani and
	Noam Shazeer and
	Niki Parmar and
	Jakob Uszkoreit and
	Llion Jones and
	Aidan N. Gomez and
	Lukasz Kaiser and
	Illia Polosukhin},
	title     = {Attention Is All You Need},
	journal   = {CoRR},
	volume    = {abs/1706.03762},
	year      = {2017},
	url       = {http://arxiv.org/abs/1706.03762},
	archivePrefix = {arXiv},
	eprint    = {1706.03762},
	timestamp = {Mon, 13 Aug 2018 16:48:37 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{1995-miller,
	author = {Miller, George A.},
	title = {WordNet: A Lexical Database for English},
	year = {1995},
	issue_date = {Nov. 1995},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {38},
	number = {11},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/219717.219748},
	doi = {10.1145/219717.219748},
	journal = {Commun. ACM},
	month = nov,
	pages = {39–41},
	numpages = {3}
}

@book {2010-ruppenhofer-al,
	author={Josef Ruppenhofer and Michael Ellsworth and Miriam R. L Petruck and Christopher R. Johnson and Collin F. Baker and Jan Scheffczyk},
	title={FrameNet II: Extended Theory and Practice},
	year={2010}, 
	publisher={berkeley university}
}

@article{2012-navigli-ponzetto,
	author = {Roberto Navigli and Simone Paolo Ponzetto},
	title =   {{B}abel{N}et: {T}he Automatic Construction, Evaluation and Application of a Wide-Coverage Multilingual Semantic Network},
	journal = {Artificial Intelligence},
	year =    {2012},
	volume = {193},
	pages = {217-250}
}

@article{2020-wang-al,
	author = {Yuxuan Wang and Yutai Hou and Wanxiang Che and Ting Liu},
	title =   {From static to dynamic word representations: a survey},
	journal = {International Journal of Machine Learning and Cybernetics},
	year =    {2020},
	issn = {1868-808X},
	doi = {https://doi.org/10.1007/s13042-020-01069-8},
	publisher= {Springer Berlin Heidelberg},
}

@article{2014-moro-al,
	author    = {Andrea Moro and
	Alessandro Raganato and
	Roberto Navigli},
	title     = {{Entity Linking meets Word Sense Disambiguation: a Unified
	Approach}},
	journal   = {Transactions of the Association for Computational Linguistics (TACL)},
	volume    = {2},
	year      = {2014},
	pages     = {231-244},
}

@Inbook{2019-white-al,
	author="White, Lyndon
	and Togneri, Roberto
	and Liu, Wei
	and Bennamoun, Mohammed",
	title="Word Sense Representations",
	bookTitle="Neural Representations of Natural Language",
	year="2019",
	publisher="Springer Singapore",
	address="Singapore",
	pages="73--92",
	abstract="In this chapter, techniques for representing the multiple meanings of a single word are discussed. This is a growing area, and is particularly important in languages where polysemous and homonymous words are common. This includes English, but it is even more prevalent in Mandarin for example. The techniques discussed can broadly be classified as lexical word sense representationWord sense representation, and as word sense inductionWord Sense Induction (WSI). The inductive techniques can be sub-classified as clusteringClustering -based or as prediction-based.",
	isbn="978-981-13-0062-2",
	doi="10.1007/978-981-13-0062-2_4",
	url="https://doi.org/10.1007/978-981-13-0062-2_4"
}

@thesis{2017-djemaa,
	author = {Marianne Djemaa},
	title = {Stratégie Domaine Par Domaine Pour
	La Création d'un Framenet Du Français :
	Annotations en Corpus de Cadres et Rôles Sémantiques
	},
	type = {Thèse de doctorat de Linguistique Théorique, Descriptive et Automatique},
	institution = {Université Sorbonne Paris Cité},
	year = {2017},
}

@book{2002-russell-norvig,
	author = {Stuart J. Russell and Peter Norvig},
	title = {Artificial Intelligence: A Modern Approach},
	year = {2002},
	edition={2nd},
	publisher={Prentice Hall},
}

@Misc{2020-cmu,
	author = {Alan W. Black and David R. Mortensen},
	title = {Compositional semantics, semantic parsing},
	howpublished = {Cours "Natural Language Processing F20"},
	year = {2020},
	note = {Carnegie Mellon University},
	annote = {\url{http://demo.clab.cs.cmu.edu/NLP/}},
}

@inproceedings{2013-banarescu-al,
	title = "{A}bstract {M}eaning {R}epresentation for Sembanking",
	author = "Banarescu, Laura  and
	Bonial, Claire  and
	Cai, Shu  and
	Georgescu, Madalina  and
	Griffitt, Kira  and
	Hermjakob, Ulf  and
	Knight, Kevin  and
	Koehn, Philipp  and
	Palmer, Martha  and
	Schneider, Nathan",
	booktitle = "Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse",
	month = aug,
	year = "2013",
	address = "Sofia, Bulgaria",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/W13-2322",
	pages = "178--186",
}


@inproceedings{2017-he-al,
	title = "Deep Semantic Role Labeling: What Works and What{'}s Next",
	author = "He, Luheng  and
	Lee, Kenton  and
	Lewis, Mike  and
	Zettlemoyer, Luke",
	booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
	month = jul,
	year = "2017",
	address = "Vancouver, Canada",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/P17-1044",
	doi = "10.18653/v1/P17-1044",
	pages = "473--483",
	abstract = "We introduce a new deep learning model for semantic role labeling (SRL) that significantly improves the state of the art, along with detailed analyses to reveal its strengths and limitations. We use a deep highway BiLSTM architecture with constrained decoding, while observing a number of recent best practices for initialization and regularization. Our 8-layer ensemble model achieves 83.2 F1 on theCoNLL 2005 test set and 83.4 F1 on CoNLL 2012, roughly a 10{\%} relative error reduction over the previous state of the art. Extensive empirical analysis of these gains show that (1) deep models excel at recovering long-distance dependencies but can still make surprisingly obvious errors, and (2) that there is still room for syntactic parsers to improve these results.",
}

@Article{info11020074,
	AUTHOR = {Ferreira Cruz, André and Rocha, Gil and Lopes Cardoso, Henrique},
	TITLE = {Coreference Resolution: Toward End-to-End and Cross-Lingual Systems},
	JOURNAL = {Information},
	VOLUME = {11},
	YEAR = {2020},
	NUMBER = {2},
	ARTICLE-NUMBER = {74},
	URL = {https://www.mdpi.com/2078-2489/11/2/74},
	ISSN = {2078-2489},
	ABSTRACT = {The task of coreference resolution has attracted considerable attention in the literature due to its importance in deep language understanding and its potential as a subtask in a variety of complex natural language processing problems. In this study, we outlined the field&rsquo;s terminology, describe existing metrics, their differences and shortcomings, as well as the available corpora and external resources. We analyzed existing state-of-the-art models and approaches, and reviewed recent advances and trends in the field, namely end-to-end systems that jointly model different subtasks of coreference resolution, and cross-lingual systems that aim to overcome the challenges of less-resourced languages. Finally, we discussed the main challenges and open issues faced by coreference resolution systems.},
	DOI = {10.3390/info11020074}
}

@inproceedings{2016-moosavi-strube,
	title = "Which Coreference Evaluation Metric Do You Trust? A Proposal for a Link-based Entity Aware Metric",
	author = "Moosavi, Nafise Sadat  and
	Strube, Michael",
	booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
	month = aug,
	year = "2016",
	address = "Berlin, Germany",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/P16-1060",
	doi = "10.18653/v1/P16-1060",
	pages = "632--642",
}

@incollection{1967-davidson,
	added-at = {2007-12-14T02:38:06.000+0100},
	author = {Davidson, Donald},
	biburl = {https://www.bibsonomy.org/bibtex/2da38166ce77b4cae007e47f2993c9ca1/diego_ma},
	booktitle = {The Logic of Decision and Action},
	editor = {Rescher, Nicholas},
	interhash = {6d48dee932e1441b38a58f96143ba0a1},
	intrahash = {da38166ce77b4cae007e47f2993c9ca1},
	keywords = {events philosophy},
	pages = {81-120},
	publisher = {Univ. of Pittsburgh Press},
	timestamp = {2007-12-14T02:38:06.000+0100},
	title = {The Logical Form of Action Sentences},
	year = 1967
}


@article{2006-Cornish,
	author = {Francis Cornish},
	title = {Relations de cohérence en discours : critères de reconnaissance, caractérisation et articulation cohésion-cohérence},
	journaltitle = {Corela [Online]},
	year = {2006},
	doi = {https://doi.org/10.4000/corela.1456},
}

@inproceedings{2008-prasad-al,
	title = "The {P}enn {D}iscourse {T}ree{B}ank 2.0.",
	author = "Prasad, Rashmi  and
	Dinesh, Nikhil  and
	Lee, Alan  and
	Miltsakaki, Eleni  and
	Robaldo, Livio  and
	Joshi, Aravind  and
	Webber, Bonnie",
	booktitle = "Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08)",
	month = may,
	year = "2008",
	address = "Marrakech, Morocco",
	publisher = "European Language Resources Association (ELRA)",
	url = "http://www.lrec-conf.org/proceedings/lrec2008/pdf/754_paper.pdf",
	abstract = "We present the second version of the Penn Discourse Treebank, PDTB-2.0, describing its lexically-grounded annotations of discourse relations and their two abstract object arguments over the 1 million word Wall Street Journal corpus. We describe all aspects of the annotation, including (a) the argument structure of discourse relations, (b) the sense annotation of the relations, and (c) the attribution of discourse relations and each of their arguments. We list the differences between PDTB-1.0 and PDTB-2.0. We present representative statistics for several aspects of the annotation in the corpus.",
}

@inproceedings{2004-lethanh-al,
	title = "Generating Discourse Structures for Written Text",
	author = "Le Thanh, Huong  and
	Abeysinghe, Geetha  and
	Huyck, Christian",
	booktitle = "{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics",
	month = "aug 23{--}aug 27",
	year = "2004",
	address = "Geneva, Switzerland",
	publisher = "COLING",
	url = "https://www.aclweb.org/anthology/C04-1048",
	pages = "329--335",
}

@inproceedings{2018-wang-al,
	title = "Toward Fast and Accurate Neural Discourse Segmentation",
	author = "Wang, Yizhong  and
	Li, Sujian  and
	Yang, Jingfeng",
	booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
	month = oct # "-" # nov,
	year = "2018",
	address = "Brussels, Belgium",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/D18-1116",
	doi = "10.18653/v1/D18-1116",
	pages = "962--967",
	abstract = "Discourse segmentation, which segments texts into Elementary Discourse Units, is a fundamental step in discourse analysis. Previous discourse segmenters rely on complicated hand-crafted features and are not practical in actual use. In this paper, we propose an end-to-end neural segmenter based on BiLSTM-CRF framework. To improve its accuracy, we address the problem of data insufficiency by transferring a word representation model that is trained on a large corpus. We also propose a restricted self-attention mechanism in order to capture useful information within a neighborhood. Experiments on the RST-DT corpus show that our model is significantly faster than previous methods, while achieving new state-of-the-art performance.",
}

@inproceedings{2018-yu-al,
	title = "Transition-based Neural {RST} Parsing with Implicit Syntax Features",
	author = "Yu, Nan  and
	Zhang, Meishan  and
	Fu, Guohong",
	booktitle = "Proceedings of the 27th International Conference on Computational Linguistics",
	month = aug,
	year = "2018",
	address = "Santa Fe, New Mexico, USA",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/C18-1047",
	pages = "559--570",
	abstract = "Syntax has been a useful source of information for statistical RST discourse parsing. Under the neural setting, a common approach integrates syntax by a recursive neural network (RNN), requiring discrete output trees produced by a supervised syntax parser. In this paper, we propose an implicit syntax feature extraction approach, using hidden-layer vectors extracted from a neural syntax parser. In addition, we propose a simple transition-based model as the baseline, further enhancing it with dynamic oracle. Experiments on the standard dataset show that our baseline model with dynamic oracle is highly competitive. When implicit syntax features are integrated, we are able to obtain further improvements, better than using explicit Tree-RNN.",
}

@article{2004-poesio-al,
	title = "{C}entering: A Parametric Theory and Its Instantiations",
	author = "Poesio, Massimo  and
	Stevenson, Rosemary  and
	Di Eugenio, Barbara  and
	Hitzeman, Janet",
	journal = "Computational Linguistics",
	volume = "30",
	number = "3",
	year = "2004",
	url = "https://www.aclweb.org/anthology/J04-3003",
	doi = "10.1162/0891201041850911",
	pages = "309--363",
}

@article{2008-barzilay-lapata,
	title = "Modeling Local Coherence: An Entity-Based Approach",
	author = "Barzilay, Regina  and
	Lapata, Mirella",
	journal = "Computational Linguistics",
	volume = "34",
	number = "1",
	year = "2008",
	url = "https://www.aclweb.org/anthology/J08-1001",
	doi = "10.1162/coli.2008.34.1.1",
	pages = "1--34",
}

@inproceedings{2020-liang-al,
	title = "Extending Implicit Discourse Relation Recognition to the {PDTB}-3",
	author = "Liang, Li  and
	Zhao, Zheng  and
	Webber, Bonnie",
	booktitle = "Proceedings of the First Workshop on Computational Approaches to Discourse",
	month = nov,
	year = "2020",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2020.codi-1.14",
	doi = "10.18653/v1/2020.codi-1.14",
	pages = "135--147",
	abstract = "The PDTB-3 contains many more Implicit discourse relations than the previous PDTB-2. This is in part because implicit relations have now been annotated within sentences as well as between them. In addition, some now co-occur with explicit discourse relations, instead of standing on their own. Here we show that while this can complicate the problem of identifying the location of implicit discourse relations, it can in turn simplify the problem of identifying their senses. We present data to support this claim, as well as methods that can serve as a non-trivial baseline for future state-of-the-art recognizers for implicit discourse relations.",
}

