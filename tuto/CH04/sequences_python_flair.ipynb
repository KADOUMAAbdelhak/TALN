{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "091f8c92",
   "metadata": {},
   "source": [
    "# Sequences tagging using flair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a1a2af",
   "metadata": {},
   "source": [
    "## I. Data preparation\n",
    "\n",
    "### I.1. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4482da9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token: 1 I,\n",
       " Token: 2 am,\n",
       " Token: 3 going,\n",
       " Token: 4 to,\n",
       " Token: 5 visit,\n",
       " Token: 6 Dr.,\n",
       " Token: 7 Watson,\n",
       " Token: 8 .,\n",
       " Token: 9 He,\n",
       " Token: 10 is,\n",
       " Token: 11 in,\n",
       " Token: 12 U.K,\n",
       " Token: 13 .]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "# make a sentence\n",
    "#sentence = Sentence('Karim bought a Lenovo computer with over 70000 DZD when he was in Algiers, Algeria.')\n",
    "\n",
    "sentence = Sentence(\"I am going to visit Dr. Watson. He is in U.K.\")\n",
    "sentence.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e527982c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token: 1 Karim,\n",
       " Token: 2 bought,\n",
       " Token: 3 a,\n",
       " Token: 4 Lenovo,\n",
       " Token: 5 computer]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# introduce a tokenized sentence\n",
    "sentence2 = Sentence(['Karim', 'bought', 'a', 'Lenovo', 'computer'])\n",
    "\n",
    "sentence2.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa1aa6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token: 1 私,\n",
       " Token: 2 は,\n",
       " Token: 3 ESI,\n",
       " Token: 4 の,\n",
       " Token: 5 先生,\n",
       " Token: 6 です,\n",
       " Token: 7 。,\n",
       " Token: 8 毎日,\n",
       " Token: 9 、,\n",
       " Token: 10 そこ,\n",
       " Token: 11 に,\n",
       " Token: 12 行き,\n",
       " Token: 13 ます,\n",
       " Token: 14 。]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use another tokenizer\n",
    "from flair.tokenization import JapaneseTokenizer\n",
    "\n",
    "# init japanese tokenizer\n",
    "ja_tokenizer = JapaneseTokenizer(\"janome\")\n",
    "\n",
    "# make sentence (and tokenize)\n",
    "sentence3 = Sentence('私はESIの先生です。毎日、そこに行きます。', use_tokenizer=ja_tokenizer)\n",
    "\n",
    "sentence3.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fcafc4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token: 1 أنا,\n",
       " Token: 2 ذاهب,\n",
       " Token: 3 إلى,\n",
       " Token: 4 السوق,\n",
       " Token: 5 .,\n",
       " Token: 6 هل,\n",
       " Token: 7 تريد,\n",
       " Token: 8 أن,\n",
       " Token: 9 أحضر,\n",
       " Token: 10 لك,\n",
       " Token: 11 شيء,\n",
       " Token: 12 ما,\n",
       " Token: 13 ؟,\n",
       " Token: 14 هكذا,\n",
       " Token: 15 إذن,\n",
       " Token: 16 !,\n",
       " Token: 17 نلتقي,\n",
       " Token: 18 بعد,\n",
       " Token: 19 أن,\n",
       " Token: 20 أعود,\n",
       " Token: 21 .]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.data import Sentence, Token, Tokenizer\n",
    "from typing import List\n",
    "import re\n",
    "\n",
    "class ArTokenizer(Tokenizer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ArTokenizer, self).__init__()\n",
    "        self.punct = re.compile(r'^(.*)([،:.,,؟!])$')\n",
    "\n",
    "    def tokenize(self, text: str) -> List[Token]:\n",
    "        words = text.split()\n",
    "        tokens: List[Token] = []\n",
    "        for word in words:\n",
    "            m = self.punct.match(word)\n",
    "            if m:\n",
    "                tokens.append(Token(m.group(1)))\n",
    "                tokens.append(Token(m.group(2)))\n",
    "            else:\n",
    "                tokens.append(Token(word))\n",
    "        return tokens\n",
    "        \n",
    "        \n",
    "\n",
    "# init arabic tokenizer\n",
    "ar_tokenizer = ArTokenizer()\n",
    "\n",
    "ar_sentence = Sentence(\"أنا ذاهب إلى السوق. هل تريد أن أحضر لك شيء ما؟ هكذا إذن! نلتقي بعد أن أعود.\", use_tokenizer=ar_tokenizer)\n",
    "\n",
    "ar_sentence.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5030f22a",
   "metadata": {},
   "source": [
    "### I.2. Corpus preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eb63264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-30 11:52:33,577 Reading data from /home/kariminf/.flair/datasets/ud_english\n",
      "2021-09-30 11:52:33,579 Train: /home/kariminf/.flair/datasets/ud_english/en_ewt-ud-train.conllu\n",
      "2021-09-30 11:52:33,581 Dev: /home/kariminf/.flair/datasets/ud_english/en_ewt-ud-dev.conllu\n",
      "2021-09-30 11:52:33,583 Test: /home/kariminf/.flair/datasets/ud_english/en_ewt-ud-test.conllu\n",
      "______ Access a sentence ______\n",
      "Sentence: \"What if Google Morphed Into GoogleOS ?\"   [− Tokens: 7  − Token-Labels: \"What <what/PRON/WP/root/Int> if <if/SCONJ/IN/mark> Google <Google/PROPN/NNP/nsubj/Sing> Morphed <morph/VERB/VBD/advcl/Ind/Past/Fin> Into <into/ADP/IN/case> GoogleOS <GoogleOS/PROPN/NNP/obl/Sing> ? <?/PUNCT/./punct>\"]\n",
      "______ PoS-tagged sentence ______\n",
      "What <WP> if <IN> Google <NNP> Morphed <VBD> Into <IN> GoogleOS <NNP> ? <.>\n"
     ]
    }
   ],
   "source": [
    "#existing corpora in flair\n",
    "import flair.datasets\n",
    "ud_en_corpus = flair.datasets.UD_ENGLISH()\n",
    "\n",
    "print('______ Access a sentence ______')\n",
    "print(ud_en_corpus.test[0])\n",
    "\n",
    "print('______ PoS-tagged sentence ______')\n",
    "print(ud_en_corpus.test[0].to_tagged_string('pos'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02af0b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-30 11:52:40,994 Reading data from .\n",
      "2021-09-30 11:52:40,996 Train: flair_train.txt\n",
      "2021-09-30 11:52:40,997 Dev: flair_dev.txt\n",
      "2021-09-30 11:52:40,997 Test: flair_test.txt\n"
     ]
    }
   ],
   "source": [
    "#creating your own corpus\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "# define columns\n",
    "columns = {0: 'text', 1: 'pos', 2: 'ner'}\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = '.'\n",
    "\n",
    "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='flair_train.txt',\n",
    "                              test_file='flair_test.txt',\n",
    "                              dev_file='flair_dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb7f03dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'un <DET> ordianteur <NOUN> peut <VERB> vous <PRON> aider <VERB>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train[0].to_tagged_string('pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8c2f07",
   "metadata": {},
   "source": [
    "## II. Part of Speech (PoS) tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4a5f90",
   "metadata": {},
   "source": [
    "### II.1. Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8a64551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-30 11:52:41,240 --------------------------------------------------------------------------------\n",
      "2021-09-30 11:52:41,242 The model key 'pos' now maps to 'https://huggingface.co/flair/pos-english' on the HuggingFace ModelHub\n",
      "2021-09-30 11:52:41,243  - The most current version of the model is automatically downloaded from there.\n",
      "2021-09-30 11:52:41,245  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/pos/en-pos-ontonotes-v0.5.pt)\n",
      "2021-09-30 11:52:41,247 --------------------------------------------------------------------------------\n",
      "2021-09-30 11:52:42,344 loading file /home/kariminf/.flair/models/pos-english/a9a73f6cd878edce8a0fa518db76f441f1cc49c2525b2b4557af278ec2f0659e.121306ea62993d04cd1978398b68396931a39eb47754c8a06a87f325ea70ac63\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "\n",
    "# load the PoS tagger\n",
    "pos_tagger = SequenceTagger.load('pos')\n",
    "\n",
    "# run PoS over sentence\n",
    "pos_tagger.predict(sentence)\n",
    "\n",
    "del pos_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86619443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRP 0.9999998807907104\n",
      "am VBP 0.9999998807907104\n",
      "going VBG 1.0\n",
      "to TO 0.9994309544563293\n",
      "visit VB 0.9999971389770508\n",
      "Dr. NNP 0.9999998807907104\n",
      "Watson NNP 1.0\n",
      ". . 0.9994010925292969\n",
      "He PRP 1.0\n",
      "is VBZ 0.9999998807907104\n",
      "in IN 0.9999984502792358\n",
      "U.K NNP 0.9999973773956299\n",
      ". . 0.9999960660934448\n"
     ]
    }
   ],
   "source": [
    "for entity in sentence.get_spans('pos'):\n",
    "    print(entity.text, entity.tag, entity.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe94a2c1",
   "metadata": {},
   "source": [
    "### II.2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b12ad9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-30 11:52:48,348 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 2280.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-30 11:52:48,360 Corpus contains the labels: pos (#25), ner (#24)\n",
      "2021-09-30 11:52:48,361 Created (for label 'pos') Dictionary with 4 tags: DET, NOUN, VERB, PRON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<flair.data.Dictionary at 0x7f32d6f3fe50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. get the corpus\n",
    "# we will use the corpus we created earlier \n",
    "\n",
    "# 2. what label do we want to predict?\n",
    "pos_label_type = 'pos'\n",
    "\n",
    "# 3. make the label dictionary from the corpus\n",
    "pos_label_dict = corpus.make_label_dictionary(label_type=pos_label_type)\n",
    "\n",
    "pos_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3252041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackedEmbeddings(\n",
       "  (list_embedding_0): WordEmbeddings('glove')\n",
       "  (list_embedding_1): CharacterEmbeddings(\n",
       "    (char_embedding): Embedding(275, 25)\n",
       "    (char_rnn): LSTM(25, 25, bidirectional=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.embeddings import WordEmbeddings, StackedEmbeddings, CharacterEmbeddings\n",
    "\n",
    "# 4. initialize embeddings\n",
    "pos_embedding_types = [\n",
    "\n",
    "    WordEmbeddings('glove'),\n",
    "\n",
    "    # comment in this line to use character embeddings\n",
    "    CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings\n",
    "    # FlairEmbeddings('news-forward'),\n",
    "    # FlairEmbeddings('news-backward'),\n",
    "]\n",
    "\n",
    "pos_embeddings = StackedEmbeddings(embeddings=pos_embedding_types)\n",
    "\n",
    "pos_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e73a14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceTagger(\n",
       "  (embeddings): StackedEmbeddings(\n",
       "    (list_embedding_0): WordEmbeddings('glove')\n",
       "    (list_embedding_1): CharacterEmbeddings(\n",
       "      (char_embedding): Embedding(275, 25)\n",
       "      (char_rnn): LSTM(25, 25, bidirectional=True)\n",
       "    )\n",
       "  )\n",
       "  (word_dropout): WordDropout(p=0.05)\n",
       "  (locked_dropout): LockedDropout(p=0.5)\n",
       "  (embedding2nn): Linear(in_features=150, out_features=150, bias=True)\n",
       "  (rnn): LSTM(150, 10, batch_first=True, bidirectional=True)\n",
       "  (linear): Linear(in_features=20, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "pos_tagger = SequenceTagger(hidden_size=10,\n",
    "                        embeddings=pos_embeddings,\n",
    "                        tag_dictionary=pos_label_dict,\n",
    "                        tag_type=pos_label_type,\n",
    "                        use_crf=True)\n",
    "\n",
    "pos_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86a5330b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-30 11:52:53,112 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:52:53,114 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('glove')\n",
      "    (list_embedding_1): CharacterEmbeddings(\n",
      "      (char_embedding): Embedding(275, 25)\n",
      "      (char_rnn): LSTM(25, 25, bidirectional=True)\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=150, out_features=150, bias=True)\n",
      "  (rnn): LSTM(150, 10, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=20, out_features=6, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-09-30 11:52:53,116 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:52:53,118 Corpus: \"Corpus: 6 train + 4 dev + 2 test sentences\"\n",
      "2021-09-30 11:52:53,121 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:52:53,122 Parameters:\n",
      "2021-09-30 11:52:53,123  - learning_rate: \"0.1\"\n",
      "2021-09-30 11:52:53,124  - mini_batch_size: \"10\"\n",
      "2021-09-30 11:52:53,125  - patience: \"3\"\n",
      "2021-09-30 11:52:53,126  - anneal_factor: \"0.5\"\n",
      "2021-09-30 11:52:53,127  - max_epochs: \"5\"\n",
      "2021-09-30 11:52:53,127  - shuffle: \"True\"\n",
      "2021-09-30 11:52:53,131  - train_with_dev: \"False\"\n",
      "2021-09-30 11:52:53,132  - batch_growth_annealing: \"False\"\n",
      "2021-09-30 11:52:53,133 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:52:53,134 Model training base path: \"/home/kariminf/Data/tutoriel/flair_pos.tagger.fr\"\n",
      "2021-09-30 11:52:53,135 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:52:53,136 Device: cpu\n",
      "2021-09-30 11:52:53,137 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:52:53,138 Embeddings storage mode: cpu\n",
      "2021-09-30 11:52:53,140 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:52:53,376 epoch 1 - iter 1/1 - loss 1.76609564 - samples/sec: 42.81 - lr: 0.100000\n",
      "2021-09-30 11:52:53,377 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:52:53,378 EPOCH 1 done: loss 1.7661 - lr 0.1000000\n",
      "2021-09-30 11:52:53,429 DEV : loss 1.3105608224868774 - f1-score (micro avg)  0.3571\n",
      "2021-09-30 11:52:53,430 BAD EPOCHS (no improvement): 0\n",
      "2021-09-30 11:52:53,431 saving best model\n",
      "2021-09-30 11:52:55,579 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:52:55,620 epoch 2 - iter 1/1 - loss 1.57068014 - samples/sec: 254.59 - lr: 0.100000\n",
      "2021-09-30 11:52:55,622 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:52:55,623 EPOCH 2 done: loss 1.5707 - lr 0.1000000\n",
      "2021-09-30 11:52:55,658 DEV : loss 1.1717501878738403 - f1-score (micro avg)  0.5714\n",
      "2021-09-30 11:52:55,659 BAD EPOCHS (no improvement): 0\n",
      "2021-09-30 11:52:55,660 saving best model\n",
      "2021-09-30 11:53:00,173 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:00,225 epoch 3 - iter 1/1 - loss 1.38378493 - samples/sec: 204.12 - lr: 0.100000\n",
      "2021-09-30 11:53:00,226 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:00,226 EPOCH 3 done: loss 1.3838 - lr 0.1000000\n",
      "2021-09-30 11:53:00,264 DEV : loss 1.0271161794662476 - f1-score (micro avg)  0.5714\n",
      "2021-09-30 11:53:00,265 BAD EPOCHS (no improvement): 0\n",
      "2021-09-30 11:53:00,266 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:00,314 epoch 4 - iter 1/1 - loss 1.22344367 - samples/sec: 217.06 - lr: 0.100000\n",
      "2021-09-30 11:53:00,315 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:00,316 EPOCH 4 done: loss 1.2234 - lr 0.1000000\n",
      "2021-09-30 11:53:00,348 DEV : loss 0.9104901552200317 - f1-score (micro avg)  0.5\n",
      "2021-09-30 11:53:00,349 BAD EPOCHS (no improvement): 1\n",
      "2021-09-30 11:53:00,352 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:00,399 epoch 5 - iter 1/1 - loss 1.09290044 - samples/sec: 226.12 - lr: 0.100000\n",
      "2021-09-30 11:53:00,400 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:00,401 EPOCH 5 done: loss 1.0929 - lr 0.1000000\n",
      "2021-09-30 11:53:00,432 DEV : loss 0.7985102534294128 - f1-score (micro avg)  0.6429\n",
      "2021-09-30 11:53:00,433 BAD EPOCHS (no improvement): 0\n",
      "2021-09-30 11:53:00,435 saving best model\n",
      "2021-09-30 11:53:07,741 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:07,742 loading file /home/kariminf/Data/tutoriel/flair_pos.tagger.fr/best-model.pt\n",
      "2021-09-30 11:53:08,654 0.25\t0.25\t0.25\t0.25\n",
      "2021-09-30 11:53:08,654 \n",
      "Results:\n",
      "- F-score (micro) 0.25\n",
      "- F-score (macro) 0.125\n",
      "- Accuracy 0.25\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        VERB     0.4000    0.6667    0.5000         3\n",
      "        NOUN     0.0000    0.0000    0.0000         4\n",
      "         DET     0.0000    0.0000    0.0000         1\n",
      "        PRON     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.2500    0.2500    0.2500         8\n",
      "   macro avg     0.1000    0.1667    0.1250         8\n",
      "weighted avg     0.1500    0.2500    0.1875         8\n",
      " samples avg     0.2500    0.2500    0.2500         8\n",
      "\n",
      "2021-09-30 11:53:08,655 ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "pos_model_path = '/home/kariminf/Data/tutoriel/flair_pos.tagger.fr'\n",
    "\n",
    "# 6. initialize trainer\n",
    "trainer = ModelTrainer(pos_tagger, corpus)\n",
    "\n",
    "# 7. start training\n",
    "trainer.train(pos_model_path,\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=10, \n",
    "              max_epochs=5)\n",
    "\n",
    "del trainer\n",
    "del pos_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8f172b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-30 11:53:08,666 loading file /home/kariminf/Data/tutoriel/flair_pos.tagger.fr/best-model.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'il <PRON> peut <VERB> aider <VERB>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model you trained\n",
    "pos_load_model = SequenceTagger.load(pos_model_path + \"/best-model.pt\")\n",
    "\n",
    "# create example sentence\n",
    "sentence_fr = Sentence('il peut aider')\n",
    "\n",
    "# predict tags and print\n",
    "pos_load_model.predict(sentence_fr)\n",
    "\n",
    "sentence_fr.to_tagged_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1507e",
   "metadata": {},
   "source": [
    "## III. Named entity recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba367b6",
   "metadata": {},
   "source": [
    "### III.1. Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7c8b18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-30 11:53:11,006 --------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:11,007 The model key 'ner' now maps to 'https://huggingface.co/flair/ner-english' on the HuggingFace ModelHub\n",
      "2021-09-30 11:53:11,008  - The most current version of the model is automatically downloaded from there.\n",
      "2021-09-30 11:53:11,009  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/ner/en-ner-conll03-v0.4.pt)\n",
      "2021-09-30 11:53:11,010 --------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:11,965 loading file /home/kariminf/.flair/models/ner-english/4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "\n",
    "\n",
    "# load the NER tagger\n",
    "ner_tagger = SequenceTagger.load('ner')\n",
    "\n",
    "# run NER over sentence\n",
    "ner_tagger.predict(sentence)\n",
    "\n",
    "del ner_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a9973dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Watson PER 0.7794725894927979\n",
      "U.K LOC 0.9533657431602478\n"
     ]
    }
   ],
   "source": [
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity.text, entity.tag, entity.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cfd3d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-30 11:53:30,020 --------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:30,022 The model key 'ar-ner' now maps to 'https://huggingface.co/megantosh/flair-arabic-multi-ner' on the HuggingFace ModelHub\n",
      "2021-09-30 11:53:30,024  - The most current version of the model is automatically downloaded from there.\n",
      "2021-09-30 11:53:30,025 --------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:31,001 loading file /home/kariminf/.flair/models/flair-arabic-multi-ner/c7af7ddef4fdcc681fcbe1f37719348afd2862b12aa1cfd4f3b93bd2d77282c7.242d030cb106124f7f9f6a88fb9af8e390f581d42eeca013367a86d585ee6dd6\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "# The model is 500MB, it is so heavy\n",
    "ar_ner_tagger = SequenceTagger.load('ar-ner')\n",
    "\n",
    "\n",
    "# predict NER tags\n",
    "ar_ner_tagger.predict(ar_sentence)\n",
    "\n",
    "del ar_ner_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "023c7e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print sentence with predicted tags\n",
    "for entity in ar_sentence.get_spans('ner'):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a671805b",
   "metadata": {},
   "source": [
    "### III.2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65b76f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-30 11:53:49,398 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 3963.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-30 11:53:49,407 Corpus contains the labels: pos (#25), ner (#24)\n",
      "2021-09-30 11:53:49,408 Created (for label 'ner') Dictionary with 4 tags: O, B-PER, I-PER, B-LOC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<flair.data.Dictionary at 0x7f32ef3cb8e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. get the corpus\n",
    "# we will use the corpus we created earlier \n",
    "\n",
    "# 2. what label do we want to predict?\n",
    "ner_label_type = 'ner'\n",
    "\n",
    "# 3. make the label dictionary from the corpus\n",
    "ner_label_dict = corpus.make_label_dictionary(label_type=ner_label_type)\n",
    "\n",
    "ner_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "768aaddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackedEmbeddings(\n",
       "  (list_embedding_0): WordEmbeddings('glove')\n",
       "  (list_embedding_1): FlairEmbeddings(\n",
       "    (lm): LanguageModel(\n",
       "      (drop): Dropout(p=0.05, inplace=False)\n",
       "      (encoder): Embedding(300, 100)\n",
       "      (rnn): LSTM(100, 2048)\n",
       "      (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (list_embedding_2): FlairEmbeddings(\n",
       "    (lm): LanguageModel(\n",
       "      (drop): Dropout(p=0.05, inplace=False)\n",
       "      (encoder): Embedding(300, 100)\n",
       "      (rnn): LSTM(100, 2048)\n",
       "      (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.embeddings import WordEmbeddings, StackedEmbeddings, FlairEmbeddings\n",
    "\n",
    "# 4. initialize embeddings\n",
    "ner_embedding_types = [\n",
    "\n",
    "    WordEmbeddings('glove'),\n",
    "    FlairEmbeddings('news-forward'),\n",
    "    FlairEmbeddings('news-backward')\n",
    "]\n",
    "\n",
    "ner_embeddings = StackedEmbeddings(embeddings=ner_embedding_types)\n",
    "\n",
    "ner_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3555ba70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceTagger(\n",
       "  (embeddings): StackedEmbeddings(\n",
       "    (list_embedding_0): WordEmbeddings('glove')\n",
       "    (list_embedding_1): FlairEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (encoder): Embedding(300, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (list_embedding_2): FlairEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.05, inplace=False)\n",
       "        (encoder): Embedding(300, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_dropout): WordDropout(p=0.05)\n",
       "  (locked_dropout): LockedDropout(p=0.5)\n",
       "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
       "  (rnn): LSTM(4196, 10, batch_first=True, bidirectional=True)\n",
       "  (linear): Linear(in_features=20, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "ner_tagger = SequenceTagger(hidden_size=10,\n",
    "                        embeddings=ner_embeddings,\n",
    "                        tag_dictionary=ner_label_dict,\n",
    "                        tag_type=ner_label_type,\n",
    "                        use_crf=True)\n",
    "\n",
    "ner_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8b96dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-30 11:53:56,538 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:56,541 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('glove')\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_2): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
      "  (rnn): LSTM(4196, 10, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=20, out_features=6, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-09-30 11:53:56,541 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:56,542 Corpus: \"Corpus: 6 train + 4 dev + 2 test sentences\"\n",
      "2021-09-30 11:53:56,543 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:56,543 Parameters:\n",
      "2021-09-30 11:53:56,544  - learning_rate: \"0.1\"\n",
      "2021-09-30 11:53:56,545  - mini_batch_size: \"10\"\n",
      "2021-09-30 11:53:56,545  - patience: \"3\"\n",
      "2021-09-30 11:53:56,546  - anneal_factor: \"0.5\"\n",
      "2021-09-30 11:53:56,547  - max_epochs: \"5\"\n",
      "2021-09-30 11:53:56,547  - shuffle: \"True\"\n",
      "2021-09-30 11:53:56,548  - train_with_dev: \"False\"\n",
      "2021-09-30 11:53:56,549  - batch_growth_annealing: \"False\"\n",
      "2021-09-30 11:53:56,550 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:56,550 Model training base path: \"/home/kariminf/Data/tutoriel/flair_ner.tagger.fr\"\n",
      "2021-09-30 11:53:56,551 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:56,554 Device: cpu\n",
      "2021-09-30 11:53:56,560 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:56,562 Embeddings storage mode: cpu\n",
      "2021-09-30 11:53:56,563 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:57,518 epoch 1 - iter 1/1 - loss 1.31704632 - samples/sec: 10.54 - lr: 0.100000\n",
      "2021-09-30 11:53:57,519 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:57,520 EPOCH 1 done: loss 1.3170 - lr 0.1000000\n",
      "2021-09-30 11:53:58,508 DEV : loss 0.911648154258728 - f1-score (micro avg)  0.0\n",
      "2021-09-30 11:53:58,509 BAD EPOCHS (no improvement): 0\n",
      "2021-09-30 11:53:58,510 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:58,684 epoch 2 - iter 1/1 - loss 0.79602019 - samples/sec: 58.14 - lr: 0.100000\n",
      "2021-09-30 11:53:58,685 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:58,686 EPOCH 2 done: loss 0.7960 - lr 0.1000000\n",
      "2021-09-30 11:53:58,733 DEV : loss 0.6329435110092163 - f1-score (micro avg)  0.0\n",
      "2021-09-30 11:53:58,735 BAD EPOCHS (no improvement): 0\n",
      "2021-09-30 11:53:58,736 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:58,890 epoch 3 - iter 1/1 - loss 0.51136188 - samples/sec: 67.08 - lr: 0.100000\n",
      "2021-09-30 11:53:58,892 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:58,892 EPOCH 3 done: loss 0.5114 - lr 0.1000000\n",
      "2021-09-30 11:53:58,934 DEV : loss 0.5555949807167053 - f1-score (micro avg)  0.0\n",
      "2021-09-30 11:53:58,935 BAD EPOCHS (no improvement): 0\n",
      "2021-09-30 11:53:58,937 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:59,087 epoch 4 - iter 1/1 - loss 0.34312908 - samples/sec: 67.40 - lr: 0.100000\n",
      "2021-09-30 11:53:59,088 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:59,089 EPOCH 4 done: loss 0.3431 - lr 0.1000000\n",
      "2021-09-30 11:53:59,149 DEV : loss 0.5188944339752197 - f1-score (micro avg)  0.0\n",
      "2021-09-30 11:53:59,150 BAD EPOCHS (no improvement): 0\n",
      "2021-09-30 11:53:59,152 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:59,296 epoch 5 - iter 1/1 - loss 0.33487566 - samples/sec: 70.26 - lr: 0.100000\n",
      "2021-09-30 11:53:59,298 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:53:59,298 EPOCH 5 done: loss 0.3349 - lr 0.1000000\n",
      "2021-09-30 11:53:59,348 DEV : loss 0.44486042857170105 - f1-score (micro avg)  0.0\n",
      "2021-09-30 11:53:59,350 BAD EPOCHS (no improvement): 0\n",
      "2021-09-30 11:54:07,942 ----------------------------------------------------------------------------------------------------\n",
      "2021-09-30 11:54:07,943 Testing using last state of model ...\n",
      "2021-09-30 11:54:08,723 0.0\t0.0\t0.0\t0.0\n",
      "2021-09-30 11:54:08,724 \n",
      "Results:\n",
      "- F-score (micro) 0.0\n",
      "- F-score (macro) 0.0\n",
      "- Accuracy 0.0\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         PER     0.0000    0.0000    0.0000         2\n",
      "         LOC     0.0000    0.0000    0.0000         1\n",
      "\n",
      "   micro avg     0.0000    0.0000    0.0000         3\n",
      "   macro avg     0.0000    0.0000    0.0000         3\n",
      "weighted avg     0.0000    0.0000    0.0000         3\n",
      " samples avg     0.0000    0.0000    0.0000         3\n",
      "\n",
      "2021-09-30 11:54:08,725 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.0,\n",
       " 'dev_score_history': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " 'train_loss_history': [1.317046324412028,\n",
       "  0.7960201899210612,\n",
       "  0.5113618771235148,\n",
       "  0.34312907854715985,\n",
       "  0.3348756631215413],\n",
       " 'dev_loss_history': [tensor(0.9116),\n",
       "  tensor(0.6329),\n",
       "  tensor(0.5556),\n",
       "  tensor(0.5189),\n",
       "  tensor(0.4449)]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "ner_model_path = '/home/kariminf/Data/tutoriel/flair_ner.tagger.fr'\n",
    "\n",
    "# 6. initialize trainer\n",
    "trainer = ModelTrainer(ner_tagger, corpus)\n",
    "\n",
    "# 7. start training\n",
    "trainer.train(ner_model_path,\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=10, \n",
    "              max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1896c350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-30 11:54:08,855 loading file /home/kariminf/Data/tutoriel/flair_pos.tagger.fr/best-model.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Karim <VERB> peut <VERB> aider <VERB>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model you trained\n",
    "pos_load_model = SequenceTagger.load(pos_model_path + \"/best-model.pt\")\n",
    "\n",
    "# create example sentence\n",
    "sentence_fr = Sentence('Karim peut aider')\n",
    "\n",
    "# predict tags and print\n",
    "pos_load_model.predict(sentence_fr)\n",
    "\n",
    "sentence_fr.to_tagged_string()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
