{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0b58721",
   "metadata": {},
   "source": [
    "# Language models with NLTK\n",
    "\n",
    "NLTK affords ways to create NGrams models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d84916bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['un', 'ordianteur', 'peut', 'vous', 'aider'],\n",
       " ['il', 'veut', 'vous', 'aider'],\n",
       " ['il', 'veut', 'un', 'ordinateur'],\n",
       " ['il', 'peut', 'nager']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# suppose we have already segmented sentences\n",
    "sentences = [\n",
    "    \"un ordianteur peut vous aider\",\n",
    "    \"il veut vous aider\",\n",
    "    \"il veut un ordinateur\",\n",
    "    \"il peut nager\"\n",
    "]\n",
    "\n",
    "# we will tokenize the sentences : see the previous chapter for more complex tokenizations\n",
    "sentWords = []\n",
    "for sentence in sentences:\n",
    "    sentWords.append(sentence.split())\n",
    "\n",
    "sentWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2658d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e92765b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<s>', 'un', 'ordianteur', 'peut', 'vous', 'aider', '</s>'],\n",
       " ['<s>', 'il', 'veut', 'vous', 'aider', '</s>'],\n",
       " ['<s>', 'il', 'veut', 'un', 'ordinateur', '</s>'],\n",
       " ['<s>', 'il', 'peut', 'nager', '</s>']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "\n",
    "sentWordsPad = []\n",
    "\n",
    "for sent in sentWords:\n",
    "    sentWordsPad.append(list(pad_both_ends(sent, 2)))\n",
    "\n",
    "sentWordsPad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3566575e",
   "metadata": {},
   "source": [
    "## II. NGrams\n",
    "\n",
    "### II.1. Creating NGrams list\n",
    "\n",
    "Here we will create two lists of NGrams: Unigrams and Bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da357262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 'un'),\n",
       " ('un', 'ordianteur'),\n",
       " ('ordianteur', 'peut'),\n",
       " ('peut', 'vous'),\n",
       " ('vous', 'aider'),\n",
       " ('aider', '</s>')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "text_bigrams = [ngrams(sent, 2) for sent in sentWordsPad]\n",
    "text_unigrams = [ngrams(sent, 1) for sent in sentWordsPad]\n",
    "\n",
    "list(text_bigrams[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bd0cc2",
   "metadata": {},
   "source": [
    "### II.2. NGrams frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edf0a80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words following \"vous\" with their frequencies\n",
      "[('aider', 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm import NgramCounter\n",
    "\n",
    "#Apparently, NgramCounter modifies the structure of input list\n",
    "#So, you have to execute the previous cell every time you want to execute this one\n",
    "#I tried copy.deepcopy, but didn't work\n",
    "ngram_counts = NgramCounter(text_bigrams + text_unigrams)\n",
    "\n",
    "print('words following \"vous\" with their frequencies')\n",
    "print(sorted(ngram_counts[['vous']].items()))\n",
    "\n",
    "# (unigram count, bigram count) = (3, 2)\n",
    "ngram_counts['il'], ngram_counts[['vous']]['aider']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3eb032",
   "metadata": {},
   "source": [
    "## III. Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5798d404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'un',\n",
       " 'ordianteur',\n",
       " 'peut',\n",
       " 'vous',\n",
       " 'aider',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'il',\n",
       " 'veut',\n",
       " 'vous',\n",
       " 'aider',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'il',\n",
       " 'veut',\n",
       " 'un',\n",
       " 'ordinateur',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'il',\n",
       " 'peut',\n",
       " 'nager',\n",
       " '</s>']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm.preprocessing import flatten\n",
    "\n",
    "# One list of all words\n",
    "wordsList = list(flatten(sentWordsPad))\n",
    "\n",
    "wordsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d7a2549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>',\n",
       " '<s>',\n",
       " 'aider',\n",
       " 'il',\n",
       " 'nager',\n",
       " 'ordianteur',\n",
       " 'ordinateur',\n",
       " 'peut',\n",
       " 'un',\n",
       " 'veut',\n",
       " 'vous']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm import Vocabulary\n",
    "\n",
    "#in here, we used \"unk_cutoff=1\" in order to keep all words\n",
    "vocab = Vocabulary(wordsList, unk_cutoff=1)\n",
    "\n",
    "# show all words\n",
    "sorted(vocab.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb3c919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a word's count\n",
    "# The marker \"<UNK>\" is added for unknown words\n",
    "vocab['alien'], vocab['vous'], vocab['<UNK>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e35ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<UNK>', 'vous')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lookup a word in the vocabulary\n",
    "vocab.lookup('alien'), vocab.lookup('vous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4135014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<UNK>', 'il', 'vous', '<UNK>')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a vocabulary with a higher cutoff\n",
    "vocab2 = Vocabulary(wordsList, unk_cutoff=2)\n",
    "\n",
    "# \"nager\" exists in our text, but its frequency is less than 2\n",
    "# so, it is considered as anknown\n",
    "vocab2.lookup(['alien', 'il', 'vous', 'nager'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "409287ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2['<UNK>']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a339127a",
   "metadata": {},
   "source": [
    "## IV. Language models\n",
    "\n",
    "### IV.1. Maximum Likelihood Estimator (MLE)\n",
    "\n",
    "In here, we will use the previous components like a pipe; padding, ngrams and vocabulary. \n",
    "We will use bigrams as example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf03668a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('<s>',),\n",
       "  ('<s>', 'un'),\n",
       "  ('un',),\n",
       "  ('un', 'ordianteur'),\n",
       "  ('ordianteur',),\n",
       "  ('ordianteur', 'peut'),\n",
       "  ('peut',),\n",
       "  ('peut', 'vous'),\n",
       "  ('vous',),\n",
       "  ('vous', 'aider'),\n",
       "  ('aider',),\n",
       "  ('aider', '</s>'),\n",
       "  ('</s>',)],\n",
       " ['<s>',\n",
       "  'un',\n",
       "  'ordianteur',\n",
       "  'peut',\n",
       "  'vous',\n",
       "  'aider',\n",
       "  '</s>',\n",
       "  '<s>',\n",
       "  'il',\n",
       "  'veut',\n",
       "  'vous',\n",
       "  'aider',\n",
       "  '</s>',\n",
       "  '<s>',\n",
       "  'il',\n",
       "  'veut',\n",
       "  'un',\n",
       "  'ordinateur',\n",
       "  '</s>',\n",
       "  '<s>',\n",
       "  'il',\n",
       "  'peut',\n",
       "  'nager',\n",
       "  '</s>'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "# create a list for vocabulary and some NGrams of order (n) and (n-1)\n",
    "train, vocab = padded_everygram_pipeline(2, sentWords)\n",
    "\n",
    "#apparently, the model has an issue with iterators\n",
    "#so, I will transform them to lists explicity\n",
    "vocab_l = list(vocab)\n",
    "train_l = []\n",
    "for t in train:\n",
    "    train_l.append(list(t))\n",
    "\n",
    "train_l[0], vocab_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d7cfc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Vocabulary with cutoff=1 unk_label='<UNK>' and 12 items>\n",
      "<NgramCounter with 2 ngram orders and 44 ngrams>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm import MLE\n",
    "\n",
    "lm = MLE(2)\n",
    "lm.fit(train_l, vocab_l)\n",
    "\n",
    "print(lm.vocab)\n",
    "print(lm.counts)\n",
    "\n",
    "lm.counts[['vous']]['aider']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86962568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08333333333333333"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score('vous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad88f03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.3333333333333333)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P(aider|vous) = 2/2 = 1\n",
    "#P(peut|il) = 1/3 = 0.3333333\n",
    "lm.score('aider', ['vous']), lm.score('peut', ['il'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8fe75bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 1.4142135623730951)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model testing\n",
    "test = [('peut', 'vous'), ('vous', 'aider')]\n",
    "\n",
    "# entropy and perplexity\n",
    "lm.entropy(test), lm.perplexity(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d638a9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'il',\n",
       " 'veut',\n",
       " 'vous',\n",
       " 'aider',\n",
       " '</s>',\n",
       " '</s>',\n",
       " 'veut',\n",
       " 'un',\n",
       " 'ordianteur']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text generation\n",
    "lm.generate(10, random_seed=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c130e575",
   "metadata": {},
   "source": [
    "### IV.2. Smoothed models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d4ec6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21428571428571427, 0.13333333333333333)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm import Laplace\n",
    "\n",
    "lm_laplace = Laplace(2)\n",
    "lm_laplace.fit(train_l, vocab_l)\n",
    "#P(aider|vous) = (2+1)/(2+12) \n",
    "#P(peut|il) = (1+1)/(3+12)\n",
    "lm_laplace.score('aider', ['vous']), lm_laplace.score('peut', ['il'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89d9d31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3125, 0.16666666666666666)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm import Lidstone\n",
    "\n",
    "# gamma = 0.5\n",
    "lm_lidstone = Lidstone(0.5, 2)\n",
    "lm_lidstone.fit(train_l, vocab_l)\n",
    "#P(aider|vous) = (2+0.5)/(2+12*0.5) = 2.5/8\n",
    "#P(peut|il) = (1+0.5)/(3+12*0.5) = 1.5/9\n",
    "lm_lidstone.score('aider', ['vous']), lm_lidstone.score('peut', ['il'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d15a6a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9541666666666666, 0.3055555555555555)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm import KneserNeyInterpolated\n",
    "\n",
    "lm_keserney = KneserNeyInterpolated(2, discount=0.1)\n",
    "lm_keserney.fit(train_l, vocab_l)\n",
    "\n",
    "lm_keserney.score('aider', ['vous']), lm_keserney.score('peut', ['il'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
